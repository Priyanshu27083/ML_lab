{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiB7PXt+cKIS2AwlvzopBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanshu27083/ML_lab/blob/main/Ensemble_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVDJsBfD97SB",
        "outputId": "dda45596-9822-40e5-d82e-9def2e2c8807"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/diabetes (1).csv\")\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "df[cols_with_zero] = df[cols_with_zero].replace(0, np.nan)\n",
        "\n",
        "df[cols_with_zero] = df[cols_with_zero].fillna(df[cols_with_zero].median())\n",
        "\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Preprocessing done successfully!\")\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Testing data shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izX_aBkCFtuw",
        "outputId": "d5d8500a-4202-4f14-a0c5-bbc06d1cc044"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6    148.0           72.0           35.0    125.0  33.6   \n",
            "1            1     85.0           66.0           29.0    125.0  26.6   \n",
            "2            8    183.0           64.0           29.0    125.0  23.3   \n",
            "3            1     89.0           66.0           23.0     94.0  28.1   \n",
            "4            0    137.0           40.0           35.0    168.0  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    float64\n",
            " 2   BloodPressure             768 non-null    float64\n",
            " 3   SkinThickness             768 non-null    float64\n",
            " 4   Insulin                   768 non-null    float64\n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(6), int64(3)\n",
            "memory usage: 54.1 KB\n",
            "None\n",
            "\n",
            "Missing values in each column:\n",
            "Pregnancies                 0\n",
            "Glucose                     0\n",
            "BloodPressure               0\n",
            "SkinThickness               0\n",
            "Insulin                     0\n",
            "BMI                         0\n",
            "DiabetesPedigreeFunction    0\n",
            "Age                         0\n",
            "Outcome                     0\n",
            "dtype: int64\n",
            "\n",
            "✅ Preprocessing done successfully!\n",
            "Training data shape: (614, 8)\n",
            "Testing data shape: (154, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision trees and random forest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier # Changed from DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier # Changed from RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error,accuracy_score,precision_score,recall_score,f1_score,confusion_matrix # Corrected imports\n",
        "\n",
        "cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "df[cols_with_zero] = df[cols_with_zero].replace(0, np.nan)\n",
        "df[cols_with_zero] = df[cols_with_zero].fillna(df[cols_with_zero].median())\n",
        "\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=42) # Changed from dt_reg\n",
        "dt_clf.fit(X_train, y_train) # Changed from dt_reg\n",
        "y_pred_dt = dt_clf.predict(X_test) # Changed from dt_reg\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42) # Changed from rf_reg\n",
        "rf_clf.fit(X_train, y_train) # Changed from rf_reg\n",
        "y_pred_rf = rf_clf.predict(X_test) # Changed from rf_reg\n",
        "\n",
        "# Removed R2 and MSE as they are for regression\n",
        "print(\"Decision Tree Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_dt))\n",
        "print(\"Random Forest Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Decision Tree Precision:\", precision_score(y_test, y_pred_dt)) # Corrected function name\n",
        "print(\"Random Forest Precision:\", precision_score(y_test, y_pred_rf)) # Corrected function name\n",
        "print(\"Decision Tree Recall:\", recall_score(y_test, y_pred_dt)) # Corrected function name\n",
        "print(\"Random Forest Recall:\", recall_score(y_test, y_pred_rf)) # Corrected function name\n",
        "print(\"Decision Tree F1-score:\", f1_score(y_test, y_pred_dt)) # Added F1-score\n",
        "print(\"Random Forest F1-score:\", f1_score(y_test, y_pred_rf)) # Added F1-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhNjB3FnGe0I",
        "outputId": "cecba16d-bcdc-4b64-e6b1-28f7b340641f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Confusion Matrix:\n",
            "[[79 21]\n",
            " [28 26]]\n",
            "Random Forest Confusion Matrix:\n",
            "[[88 12]\n",
            " [22 32]]\n",
            "Decision Tree Accuracy: 0.6818181818181818\n",
            "Random Forest Accuracy: 0.7792207792207793\n",
            "Decision Tree Precision: 0.5531914893617021\n",
            "Random Forest Precision: 0.7272727272727273\n",
            "Decision Tree Recall: 0.48148148148148145\n",
            "Random Forest Recall: 0.5925925925925926\n",
            "Decision Tree F1-score: 0.5148514851485149\n",
            "Random Forest F1-score: 0.6530612244897959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix # Changed to classification metrics\n",
        "\n",
        "cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "df[cols_with_zero] = df[cols_with_zero].replace(0, np.nan)\n",
        "df[cols_with_zero] = df[cols_with_zero].fillna(df[cols_with_zero].median())\n",
        "\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "estimators = [10, 50, 100, 200, 300, 500]\n",
        "print(\"n_estimators | Accuracy | Precision | Recall | F1-score\") # Updated header\n",
        "\n",
        "for n in estimators:\n",
        "    model = RandomForestClassifier(n_estimators=n, random_state=42) # Changed from RandomForestRegressor\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"{n:<12} | {accuracy:.4f} | {precision:.4f} | {recall:.4f} | {f1:.4f}\") # Updated print format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuNj_GecI824",
        "outputId": "7b1581bd-8a7d-42aa-bd86-932e435ea6ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators | Accuracy | Precision | Recall | F1-score\n",
            "10           | 0.7100 | 0.6129 | 0.4691 | 0.5315\n",
            "50           | 0.7576 | 0.6984 | 0.5432 | 0.6111\n",
            "100          | 0.7403 | 0.6667 | 0.5185 | 0.5833\n",
            "200          | 0.7446 | 0.6719 | 0.5309 | 0.5931\n",
            "300          | 0.7403 | 0.6615 | 0.5309 | 0.5890\n",
            "500          | 0.7532 | 0.6818 | 0.5556 | 0.6122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "df[cols_with_zero] = df[cols_with_zero].replace(0, np.nan)\n",
        "df[cols_with_zero] = df[cols_with_zero].fillna(df[cols_with_zero].median())\n",
        "\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "model1 = LogisticRegression(max_iter=1000)\n",
        "model2 = DecisionTreeClassifier(random_state=42)\n",
        "model3 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "model1.fit(X_train, y_train)\n",
        "model2.fit(X_train, y_train)\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "pred1 = model1.predict(X_test)\n",
        "pred2 = model2.predict(X_test)\n",
        "pred3 = model3.predict(X_test)\n",
        "\n",
        "acc1 = accuracy_score(y_test, pred1)\n",
        "acc2 = accuracy_score(y_test, pred2)\n",
        "acc3 = accuracy_score(y_test, pred3)\n",
        "\n",
        "print(\"Individual Model Accuracies:\")\n",
        "print(\"Logistic Regression:\", acc1)\n",
        "print(\"Decision Tree:\", acc2)\n",
        "print(\"Random Forest:\", acc3)\n",
        "\n",
        "preds = np.array([pred1, pred2, pred3])\n",
        "final_pred_max = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
        "print(\"Max Voting Accuracy:\", accuracy_score(y_test, final_pred_max))\n",
        "\n",
        "proba1 = model1.predict_proba(X_test)[:, 1]\n",
        "proba2 = model2.predict_proba(X_test)[:, 1]\n",
        "proba3 = model3.predict_proba(X_test)[:, 1]\n",
        "\n",
        "avg_proba = (proba1 + proba2 + proba3) / 3\n",
        "final_pred_avg = (avg_proba >= 0.5).astype(int)\n",
        "print(\"Average Voting Accuracy:\", accuracy_score(y_test, final_pred_avg))\n",
        "\n",
        "weights = np.array([acc1, acc2, acc3])\n",
        "weighted_avg = (proba1 * weights[0] + proba2 * weights[1] + proba3 * weights[2]) / weights.sum()\n",
        "final_pred_weighted = (weighted_avg >= 0.5).astype(int)\n",
        "print(\"Weighted Average Voting Accuracy:\", accuracy_score(y_test, final_pred_weighted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-7-bwtGL5PI",
        "outputId": "005717af-cc8d-4139-8cd4-de862e87572a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Individual Model Accuracies:\n",
            "Logistic Regression: 0.7445887445887446\n",
            "Decision Tree: 0.6883116883116883\n",
            "Random Forest: 0.7402597402597403\n",
            "Max Voting Accuracy: 0.7489177489177489\n",
            "Average Voting Accuracy: 0.7575757575757576\n",
            "Weighted Average Voting Accuracy: 0.7619047619047619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Outcome']\n",
        "df = pd.read_csv(url, names=columns)\n",
        "\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "clf1 = DecisionTreeClassifier(random_state=42)\n",
        "clf2 = LogisticRegression(random_state=42, max_iter=1000)\n",
        "clf3 = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "hard_voting_clf = VotingClassifier(\n",
        "    estimators=[('dt', clf1), ('lr', clf2), ('knn', clf3)],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "soft_voting_clf = VotingClassifier(\n",
        "    estimators=[('dt', clf1), ('lr', clf2), ('knn', clf3)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "hard_voting_clf.fit(X_train_scaled, y_train)\n",
        "soft_voting_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_hard = hard_voting_clf.predict(X_test_scaled)\n",
        "y_pred_soft = soft_voting_clf.predict(X_test_scaled)\n",
        "\n",
        "print(\"Accuracy of Hard Voting Classifier:\", accuracy_score(y_test, y_pred_hard))\n",
        "print(\"Accuracy of Soft Voting Classifier:\", accuracy_score(y_test, y_pred_soft))\n",
        "\n",
        "for clf, name in zip([clf1, clf2, clf3], ['Decision Tree', 'Logistic Regression', 'KNN']):\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    print(f\"Accuracy of {name}: {accuracy_score(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Aw2tnQjRr6Q",
        "outputId": "5b12b9da-0bf3-4ddf-9fb7-7b1582ffbe29"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Hard Voting Classifier: 0.7575757575757576\n",
            "Accuracy of Soft Voting Classifier: 0.7922077922077922\n",
            "Accuracy of Decision Tree: 0.7619047619047619\n",
            "Accuracy of Logistic Regression: 0.7445887445887446\n",
            "Accuracy of KNN: 0.7142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Pima Indians Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI',\n",
        "           'DiabetesPedigreeFunction','Age','Outcome']\n",
        "df = pd.read_csv(url, names=columns)\n",
        "\n",
        "# 2. Separate features and target\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "# 3. Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 4. Standardize features (good for most models)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 5. Function to train Random Forest with different parameters\n",
        "def train_random_forest(n_estimators=100, max_depth=None, random_state=42):\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    rf.fit(X_train_scaled, y_train)\n",
        "    y_train_pred = rf.predict(X_train_scaled)\n",
        "    y_test_pred = rf.predict(X_test_scaled)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Random Forest (n_estimators={n_estimators}, max_depth={max_depth}, random_state={random_state})\")\n",
        "    print(f\"  Training Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_acc:.4f}\\n\")\n",
        "    return rf\n",
        "\n",
        "# 6. Experiment 1: Change number of estimators\n",
        "print(\"=== Experiment 1: Varying n_estimators ===\")\n",
        "for n in [10, 50, 100, 200]:\n",
        "    train_random_forest(n_estimators=n)\n",
        "\n",
        "# 7. Experiment 2: Change max_depth\n",
        "print(\"=== Experiment 2: Varying max_depth ===\")\n",
        "for depth in [None, 3, 5, 7]:\n",
        "    train_random_forest(max_depth=depth)\n",
        "\n",
        "# 8. Experiment 3: Change random_state\n",
        "print(\"=== Experiment 3: Varying random_state ===\")\n",
        "for rs in [0, 42, 100]:\n",
        "    train_random_forest(random_state=rs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5k7ESYaUtB4",
        "outputId": "1832cc46-ef30-4176-bf38-d96f9cc15608"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Experiment 1: Varying n_estimators ===\n",
            "Random Forest (n_estimators=10, max_depth=None, random_state=42)\n",
            "  Training Accuracy: 0.9907\n",
            "  Test Accuracy: 0.7229\n",
            "\n",
            "Random Forest (n_estimators=50, max_depth=None, random_state=42)\n",
            "  Training Accuracy: 1.0000\n",
            "  Test Accuracy: 0.7359\n",
            "\n",
            "Random Forest (n_estimators=100, max_depth=None, random_state=42)\n",
            "  Training Accuracy: 1.0000\n",
            "  Test Accuracy: 0.7532\n",
            "\n",
            "Random Forest (n_estimators=200, max_depth=None, random_state=42)\n",
            "  Training Accuracy: 1.0000\n",
            "  Test Accuracy: 0.7619\n",
            "\n",
            "=== Experiment 2: Varying max_depth ===\n",
            "Random Forest (n_estimators=100, max_depth=None, random_state=42)\n",
            "  Training Accuracy: 1.0000\n",
            "  Test Accuracy: 0.7532\n",
            "\n",
            "Random Forest (n_estimators=100, max_depth=3, random_state=42)\n",
            "  Training Accuracy: 0.7952\n",
            "  Test Accuracy: 0.7359\n",
            "\n",
            "Random Forest (n_estimators=100, max_depth=5, random_state=42)\n",
            "  Training Accuracy: 0.8678\n",
            "  Test Accuracy: 0.7532\n",
            "\n",
            "Random Forest (n_estimators=100, max_depth=7, random_state=42)\n",
            "  Training Accuracy: 0.9385\n",
            "  Test Accuracy: 0.7619\n",
            "\n",
            "=== Experiment 3: Varying random_state ===\n",
            "Random Forest (n_estimators=100, max_depth=None, random_state=0)\n",
            "  Training Accuracy: 1.0000\n",
            "  Test Accuracy: 0.7489\n",
            "\n",
            "Random Forest (n_estimators=100, max_depth=None, random_state=42)\n",
            "  Training Accuracy: 1.0000\n",
            "  Test Accuracy: 0.7532\n",
            "\n",
            "Random Forest (n_estimators=100, max_depth=None, random_state=100)\n",
            "  Training Accuracy: 0.9981\n",
            "  Test Accuracy: 0.7576\n",
            "\n"
          ]
        }
      ]
    }
  ]
}